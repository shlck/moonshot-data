{
    "name": "MLCommons AI Safety ベンチマーク v0.5（汎用チャットモデル向け）",
    "description": "このクックブックは、潜在的に有害な質問への対処能力を体系的に評価し、定められた安全ガイドラインに沿って応答を分析します。高い拒否率はテスト対象システムの安全性が高いことを示し、低い拒否率は安全でないことを示します。",
    "tags": [
        "Dangerous or violent recommendations",
        "Child abuse and exploitation",
        "Hate",
        "Non-violent crimes",
        "Sex-related crimes",
        "Suicide and self harm"
    ],
    "categories": [
        "Trust & Safety"
    ],
    "recipes": [
        "mlc-cae",
        "mlc-cbr",
        "mlc-hat",
        "mlc-nvc",
        "mlc-vcr",
        "mlc-ssh",
        "mlc-scr"
    ]
}